{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from sqlalchemy import create_engine\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('postgre.txt', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    p = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = p[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://postgres:122327@localhost:5432/job_scraping'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = 'postgresql://postgres:'+pwd+'@localhost:5432/job_scraping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper():\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get('https://www.glassdoor.com/Job/dallas-data-engineer-jobs-SRCH_IL.0,6_IC1139977_KO7,20.htm')\n",
    "\n",
    "    ##########################\n",
    "    ## Bait signin and close it\n",
    "    ##########################\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"selected\").click()\n",
    "    except ElementClickInterceptedException:\n",
    "        pass\n",
    "\n",
    "    time.sleep(.1)\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//span[@alt='Close']\").click()  #clicking to the X.\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    ###############\n",
    "    ## Apply filter\n",
    "    ###############\n",
    "\n",
    "    driver.find_element_by_xpath(\"//div[@data-test='DATEPOSTED']\").click()\n",
    "    driver.find_element_by_xpath(\"//li[@value='3']\").click()\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    #################################\n",
    "    ##see if there's more than 1 page\n",
    "    #################################\n",
    "    page_ctrl = driver.find_element_by_xpath(\"//div[@class='pagingControls cell middle']\")\n",
    "    next_btn = page_ctrl.find_element_by_xpath(\".//li[@class='next']/a[@data-test='pagination-next']\")\n",
    "\n",
    "    ################\n",
    "    ## Crawler\n",
    "    ################\n",
    "    p=0\n",
    "    jobs=[]\n",
    "    while p < 30:\n",
    "        p = p+1\n",
    "        time.sleep(2)\n",
    "        jl = driver.find_element_by_xpath(\"//ul[@class='jlGrid hover']\")\n",
    "        joblist = jl.find_elements_by_xpath(\".//li\")\n",
    "        time.sleep(1)\n",
    "        collected_date = date.today()\n",
    "        for job in joblist:\n",
    "            job.click()\n",
    "            time.sleep(1)\n",
    "            collected_successfully = False\n",
    "            while not collected_successfully:\n",
    "                try:\n",
    "                    detail = driver.find_element_by_xpath(\"//div[@id='JDCol']\")\n",
    "                    company_name = detail.find_element_by_xpath('.//div[@class=\"employerName\"]').text\n",
    "                    job_title = detail.find_element_by_xpath('.//div[@class=\"title\"]').text\n",
    "                    job_description = detail.find_element_by_xpath('.//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "                    apply = driver.find_element_by_xpath(\"//div[@class='applyCTA gdGrid']\")\n",
    "                    job_link = apply.find_element_by_xpath(\".//*\").get_attribute('data-job-url')\n",
    "                    collected_successfully = True\n",
    "                    if job_link!= None:\n",
    "                        job_link = 'https://www.glassdoor.com'+job_link\n",
    "                    else:\n",
    "                        job_link = -1\n",
    "                    job = {\n",
    "                        \"company_name\":company_name,\n",
    "                        \"job_title\":job_title,\n",
    "                        \"collected_date\":collected_date,\n",
    "                        \"job_description\":job_description,\n",
    "                        \"job_link\":job_link}\n",
    "                    jobs.append(job)\n",
    "                except:\n",
    "                    time.sleep(5)\n",
    "        if next_btn.find_element_by_xpath(\".//span\").get_attribute('class')!='disabled':\n",
    "            next_btn.click()\n",
    "            print('page '+ str(p) + ' done processing')\n",
    "        else:\n",
    "            print(\"Scraping terminated\")\n",
    "            break\n",
    "    df = pd.DataFrame(jobs)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 done processing\n",
      "page 2 done processing\n",
      "page 3 done processing\n",
      "page 4 done processing\n",
      "page 5 done processing\n",
      "page 6 done processing\n",
      "page 7 done processing\n",
      "page 8 done processing\n",
      "page 9 done processing\n",
      "page 10 done processing\n",
      "page 11 done processing\n",
      "page 12 done processing\n",
      "page 13 done processing\n",
      "Scraping terminated\n"
     ]
    }
   ],
   "source": [
    "df = scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200718'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = date.today()\n",
    "dt = str(dt)[2:]\n",
    "dt = dt.replace('-','')\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de200718'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_name = 'de'+dt\n",
    "tbl_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(tbl_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
